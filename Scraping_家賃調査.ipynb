{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping_家賃調査.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6pJbi4H9Vq6JnEGly7Xf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/Scraping/blob/main/Scraping_%E5%AE%B6%E8%B3%83%E8%AA%BF%E6%9F%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm5pfPMGiBXc"
      },
      "source": [
        "# モジュールのimport\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm as tqdm #for文使うときは必ずつける。\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFOle7IdiSaK",
        "outputId": "1543155a-3440-4860-a5f8-adb5bb9f5233"
      },
      "source": [
        "# スクレイピングした要素を入れる空のリストを作成。\n",
        "house_name=[]\n",
        "price=[]\n",
        "kanrihi=[]\n",
        "sikikin=[]\n",
        "reikin=[]\n",
        "hosyokin=[]\n",
        "sikibiki=[]\n",
        "address=[]\n",
        "nearest_station=[]\n",
        "layout=[]\n",
        "area=[]\n",
        "age=[]\n",
        "floor=[]\n",
        "direction=[]\n",
        "house_type=[]\n",
        "construction=[]\n",
        "floor_max=[]\n",
        "insurance=[]\n",
        "parking=[]\n",
        "separate_bath=[]\n",
        "elevator=[]\n",
        "pet=[]\n",
        "washing_machin=[]\n",
        "auto_lock=[]\n",
        "washroom=[]\n",
        "url_syosai_lists=[]\n",
        "\n",
        "# urlの最後に&page=1をつけると１ページ目、&page=2だと２ページ目が表示されるので、まずページ数をfor文で回す。\n",
        "# rangeの80はだいたい75ページだったから。スクレイピング中にページ数が変わるかもしれないので大体で良い。\n",
        "\n",
        "for h in tqdm(range(1,80)):\n",
        "    try:\n",
        "        h=str(h)\n",
        "        # 桶川市\n",
        "        url=\"https://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ra=011&cb=0.0&ct=9999999&et=9999999&cn=9999999&mb=0&mt=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&fw2=&ek=040506730&rn=0405\" + \"&page=\" + h\n",
        "        urls=requests.get(url)\n",
        "        urls.encoding=urls.apparent_encoding #これ地味に時間かかる\n",
        "        soup=BeautifulSoup(urls.content,\"html.parser\")\n",
        "        syosai=soup.find_all(\"a\",class_=\"js-cassette_link_href cassetteitem_other-linktext\") #詳細を見るのリンクを全て取得。\n",
        "\n",
        "        for i in range(len(syosai)): #上記で取得したsyosaiを１つずつ取り出し、そｎi番目のhrefタグを取り出し、url_syosaiにする。\n",
        "            id_href=syosai[i].get(\"href\")# URLは\"href\"タグにある。\n",
        "            url_syosai=\"https://suumo.jp\" + id_href\n",
        "            url_syosai_lists.append(url_syosai)\n",
        "        time.sleep(1) #サーバーに負荷がかかるので１秒待つ。\n",
        "\n",
        "    except IndexError: #ページ数はだいたいなのでエラーが出ても続けるようにする。\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 22/79 [01:48<04:40,  4.92s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJmGdgetiV2H"
      },
      "source": [
        "#上記のスクレイピングが終わるとurl_syosai_listsに１つ１つの物件のURLが入る。それを取り出し、要素を取得してく。\n",
        "for j in tqdm(range(len(url_syosai_lists))):\n",
        "    try:\n",
        "        url=url_syosai_lists[j]\n",
        "        urls=requests.get(url)\n",
        "        time.sleep(1) #サーバーに負荷がかかるので１秒待つ。\n",
        "        urls.encoding=urls.apparent_encoding\n",
        "        soup=BeautifulSoup(urls.content,\"html.parser\")\n",
        "\n",
        "        details_df_1=pd.read_html(url)[2]\n",
        "        details_df_2=pd.read_html(url)[3]\n",
        "\n",
        "        house_name.append(soup.find(class_=\"section_h1-header-title\").text) #家の名前\n",
        "        price.append(soup.find(class_=\"property_view_note-list\").find_all(\"span\")[0].text) #家賃\n",
        "        kanrihi.append(soup.find(class_=\"property_view_note-list\").find_all(\"span\")[1].text.split(\"\\xa0\")[1]) #スクレイピングすると「\\xa0」が混ざってしまうのでsplitして１個目を取得 #管理費\n",
        "        sikikin.append(soup.find_all(class_=\"property_view_note-list\")[1].find_all(\"span\")[0].text.split(\"\\xa0\")[1]) #敷金\n",
        "        reikin.append(soup.find_all(class_=\"property_view_note-list\")[1].find_all(\"span\")[1].text.split(\"\\xa0\")[1]) #礼金\n",
        "        hosyokin.append(soup.find_all(class_=\"property_view_note-list\")[1].find_all(\"span\")[2].text.split(\"\\xa0\")[1]) #保証金\n",
        "        sikibiki.append(soup.find_all(class_=\"property_view_note-list\")[1].find_all(\"span\")[3].text.split(\"\\xa0\")[1]) #敷引\n",
        "        address.append(details_df_1.iloc[0,1:4][1]) #住所\n",
        "        nearest_station.append(details_df_1.iloc[1,1:4][1]) #最寄り駅、徒歩\n",
        "        layout.append(details_df_1.iloc[2,1:2][1]) #間取り。1LDKとか\n",
        "        area.append(details_df_1.iloc[2,3:4][3]) #専有面積\n",
        "        age.append(details_df_1.iloc[3,1:2][1]) #築年数\n",
        "        floor.append(details_df_1.iloc[3,3:4][3]) #何階か\n",
        "        direction.append(details_df_1.iloc[4,1:2][1]) #方角。南向きとか。\n",
        "        house_type.append(details_df_1.iloc[4,3:4][3]) #マンションorアパートなど\n",
        "        construction.append(details_df_2.iloc[0,3:4][3]) #鉄筋、木造など\n",
        "        floor_max.append(details_df_2.iloc[1,1:2][1]) #何回まであるか。2階/5階など\n",
        "        insurance.append(details_df_2.iloc[2,1:2][1]) #保証について\n",
        "        parking.append(details_df_2.iloc[2,3:4][3]) #駐車場の有無\n",
        "        # 設備については全て取り出すのは大変なので個人的に気になるやつを取得\n",
        "        setsubi=soup.find_all(class_=\"inline_list\")[1]\n",
        "        text=str(setsubi)\n",
        "        text=text.split(\"、\")\n",
        "\n",
        "        # バストイレ別なら「1」、別じゃないなら「0」。他も同様。\n",
        "        if '<ul class=\"inline_list\">\\n<li>バストイレ別' in text:\n",
        "            separate_bath.append(1)\n",
        "        else:\n",
        "            separate_bath.append(0)\n",
        "\n",
        "        if \"エレベーター\" in text: #エレベーターの有無\n",
        "            elevator.append(1)\n",
        "        else:\n",
        "            elevator.append(0)\n",
        "\n",
        "        if \"ペット\" in text: #ペットOKか\n",
        "            pet.append(1)\n",
        "        else:\n",
        "            pet.append(0)\n",
        "\n",
        "        if \"室内洗濯置\" in text: #室内に洗濯機がおけるか\n",
        "            washing_machin.append(1)\n",
        "        else:\n",
        "            washing_machin.append(0)\n",
        "\n",
        "        if \"オートロック\" in text: #オートロックの有無\n",
        "            auto_lock.append(1)\n",
        "        else:\n",
        "            auto_lock.append(0)\n",
        "\n",
        "        if \"洗面所独立\" in text: #独立洗面台の有無\n",
        "            washroom.append(1)\n",
        "        else:\n",
        "            washroom.append(0)\n",
        "\n",
        "    except AttributeError:\n",
        "        continue    \n",
        "\n",
        "# 得られたリストを全てSeriesに変換、結合していく。\n",
        "house_name_s=pd.Series(house_name)     \n",
        "price_s=pd.Series(price)\n",
        "kanrihi_s=pd.Series(kanrihi)\n",
        "sikikin_s=pd.Series(sikikin)\n",
        "reikin_s=pd.Series(reikin)\n",
        "hosyokin_s=pd.Series(hosyokin)\n",
        "sikibiki_s=pd.Series(sikibiki)\n",
        "address_s=pd.Series(address)\n",
        "nearest_station_s=pd.Series(nearest_station)\n",
        "layout_s=pd.Series(layout)\n",
        "area_s=pd.Series(area)\n",
        "age_s=pd.Series(age)\n",
        "floor_s=pd.Series(floor)\n",
        "direction_s=pd.Series(direction)\n",
        "house_type_s=pd.Series(house_type)\n",
        "construction_s=pd.Series(construction)\n",
        "floor_max_s=pd.Series(floor_max)\n",
        "insurance_s=pd.Series(insurance)\n",
        "parking_s=pd.Series(parking)\n",
        "separate_bath_s=pd.Series(separate_bath)\n",
        "elevator_s=pd.Series(elevator)\n",
        "pet_s=pd.Series(pet)\n",
        "washing_machin_s=pd.Series(washing_machin)\n",
        "auto_lock_s=pd.Series(auto_lock)\n",
        "washroom_s=pd.Series(washroom)\n",
        "\n",
        "df=pd.concat([house_name_s,price_s,kanrihi_s,sikikin_s,reikin_s,hosyokin_s,sikibiki_s,\\\n",
        "              address_s,nearest_station_s,layout_s,area_s,age_s,floor_s,direction_s,house_type_s,\\\n",
        "              construction_s,floor_max_s,insurance_s,parking_s,separate_bath_s,\\\n",
        "              elevator_s,pet_s,washing_machin_s,auto_lock_s,washroom_s],axis=1)\n",
        "\n",
        "df.columns=[\"house_name\",\"price\",\"kanrihi\",\"sikikin\",\"reikin\",\"hosyokin\",\"sikibiki\",\"address\",\\\n",
        "            \"nearest_station\",\"layout\",\"area\",\"age\",\"floor\",\"direction\",\"house_type\",\"construction\",\"floor_max\",\\\n",
        "           \"insurance\",\"parking\",\"separate_bath\",\"elevator\",\"pet\",\"washing_machin\",\"auto_lock\",\"washroom\"]\n",
        "\n",
        "df.to_csv('suumo.csv',header=True, index=False) # csvに保存"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}